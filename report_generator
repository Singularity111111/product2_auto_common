import os
import glob
import pandas as pd
import openpyxl
from openpyxl.utils import column_index_from_string
from datetime import datetime
import shutil

# =============================== CONFIGURATION ==================================
SOURCE_EXCEL_NAME = '需要覆盖的文件.xlsx'
OUTPUT_EXCEL_NAME = SOURCE_EXCEL_NAME.replace('.xlsx', '_updated_final.xlsx')

REPORT_MAP = {
    '运营统计': ('后台', '时间', 'C', 'update_or_append'),
    'LTV全平台': ('LTV', '时间', 'C', 'update_or_append'),
    '用户留存率(首充复登)_全平台': ('首充复登', '时间', 'I', 'update_and_sort'),
    '用户留存率(首充复充)_全平台': ('首充复充', '时间', 'J', 'update_and_sort'),
    '推广渠道统计-渠道质量': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '推广渠道统计-用户质量': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '推广渠道统计-经济效益': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '赠送类型统计': ('赠送类型统计', '日期', 'A', 'append_all'),
    '每日渠道统计': ('每日渠道统计', '日期', 'A', 'append_all'),
}
# ========================================================================

def to_datetime_obj(value):
    if isinstance(value, datetime):
        return value
    if pd.isna(value) or value is None or str(value).strip() == '':
        return None
    try:
        return pd.to_datetime(str(value))
    except (ValueError, TypeError):
        return None

def run_update():
    current_directory = os.getcwd()
    source_path = os.path.join(current_directory, SOURCE_EXCEL_NAME)
    output_path = os.path.join(current_directory, OUTPUT_EXCEL_NAME)

    print(f"--- Starting Smart Update ---")
    try:
        shutil.copy(source_path, output_path)
        print(f"✓ Safe copy created: {OUTPUT_EXCEL_NAME}")
    except Exception as e:
        print(f"\n[ERROR] Failed to create a copy: {e}")
        return

    csv_files = glob.glob(os.path.join(current_directory, '*.csv'))
    print(f"✓ Found {len(csv_files)} CSV files to process...")

    workbook = openpyxl.load_workbook(output_path)

    for csv_path in csv_files:
        filename = os.path.basename(csv_path)
        mapping = None
        for keyword, value in sorted(REPORT_MAP.items(), key=lambda item: len(item[0]), reverse=True):
            if keyword in filename:
                mapping = value
                break
        
        if not mapping:
            continue

        sheet_name, date_col_name_csv, date_col_letter_excel, strategy = mapping
        date_col_idx_excel = column_index_from_string(date_col_letter_excel)
        print(f"\n+ Processing '{filename}' -> Sheet: '{sheet_name}' (Strategy: {strategy})")

        try:
            source_df = pd.read_csv(csv_path, keep_default_na=False, dtype=str)
            if source_df.empty:
                print("  - INFO: CSV file is empty, skipping.")
                continue
            
            source_df = source_df[~source_df[date_col_name_csv].astype(str).str.contains("数据汇总")]
            source_df = source_df[source_df[date_col_name_csv].astype(str).str.strip() != '']
            if source_df.empty:
                print("  - INFO: CSV has no valid data rows after cleaning, skipping.")
                continue

            sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(title=sheet_name)

            if strategy == 'update_or_append':
                date_to_row_map = {}
                for row_idx in range(1, sheet.max_row + 1):
                    cell_value = sheet.cell(row=row_idx, column=date_col_idx_excel).value
                    date_obj = to_datetime_obj(cell_value)
                    if date_obj:
                        date_to_row_map[date_obj.strftime('%Y-%m-%d')] = row_idx

                rows_to_append_df, updated_count = [], 0
                for index, source_row in source_df.iterrows():
                    csv_date_obj = to_datetime_obj(source_row[date_col_name_csv])
                    if not csv_date_obj: continue
                    csv_date_key = csv_date_obj.strftime('%Y-%m-%d')
                    
                    if csv_date_key in date_to_row_map:
                        target_row_num = date_to_row_map[csv_date_key]
                        for col_offset, value in enumerate(source_row.values):
                            sheet.cell(row=target_row_num, column=date_col_idx_excel + col_offset, value=value)
                        updated_count += 1
                    else:
                        rows_to_append_df.append(source_row)
                
                if rows_to_append_df:
                    for row_to_append in pd.DataFrame(rows_to_append_df).itertuples(index=False):
                        sheet.append([None] * (date_col_idx_excel - 1) + list(row_to_append))
                print(f"  ✓ Done: Updated {updated_count} rows and appended {len(rows_to_append_df)} new rows.")

            # =================== FINAL 'update_and_sort' LOGIC ===================
            elif strategy == 'update_and_sort':
                header_row_index = -1
                for i in range(1, min(21, sheet.max_row + 1)):
                    row_values = [str(c.value) for c in sheet[i]]
                    if date_col_name_csv in row_values:
                        header_row_index = i
                        break
                
                if header_row_index == -1:
                    print(f"  - ERROR: Could not find header row with '{date_col_name_csv}'. Skipping.")
                    continue

                # ** THE FIX: Correctly identify the start of data after multi-line headers **
                data_start_row = header_row_index + 2

                excel_data_rows = []
                num_excel_cols = len(source_df.columns)
                for row in sheet.iter_rows(min_row=data_start_row, values_only=True):
                    if len(row) >= date_col_idx_excel and row[date_col_idx_excel - 1] is not None:
                        # Slice the row to match the number of columns in the CSV
                        row_slice = list(row[date_col_idx_excel - 1 : date_col_idx_excel - 1 + num_excel_cols])
                        excel_data_rows.append(row_slice)

                excel_df = pd.DataFrame(excel_data_rows, columns=source_df.columns)

                excel_df.dropna(subset=[date_col_name_csv], inplace=True)
                source_df.dropna(subset=[date_col_name_csv], inplace=True)

                excel_df[date_col_name_csv] = excel_df[date_col_name_csv].apply(to_datetime_obj)
                source_df[date_col_name_csv] = source_df[date_col_name_csv].apply(to_datetime_obj)

                combined_df = pd.concat([excel_df, source_df], ignore_index=True)
                combined_df.drop_duplicates(subset=[date_col_name_csv], keep='last', inplace=True)
                combined_df.sort_values(by=date_col_name_csv, inplace=True)

                # ** THE FIX: Use safer "overwrite-and-clear" method instead of deleting rows **
                num_new_rows = len(combined_df)
                max_existing_data_row = sheet.max_row
                
                # Overwrite data row by row
                for i, data_row in enumerate(combined_df.itertuples(index=False)):
                    target_excel_row = data_start_row + i
                    # Write data starting from the correct date column
                    for j, value in enumerate(data_row):
                        # Convert datetime back to string for consistent format if needed
                        if isinstance(value, pd.Timestamp):
                            value = value.strftime('%Y-%m-%d %H:%M:%S')
                        sheet.cell(row=target_excel_row, column=date_col_idx_excel + j, value=value)
                
                # Clear any leftover old rows if the new data is shorter
                last_new_row_index = data_start_row + num_new_rows -1
                if max_existing_data_row > last_new_row_index:
                    for row_to_clear in range(last_new_row_index + 1, max_existing_data_row + 1):
                        for col_to_clear in range(date_col_idx_excel, date_col_idx_excel + num_excel_cols):
                            sheet.cell(row=row_to_clear, column=col_to_clear, value=None)

                print(f"  ✓ Done: Safely rebuilt and sorted data. Final sheet has {num_new_rows} data rows.")

            elif strategy == 'update_in_place':
                excel_headers_map = {}
                for r_idx in range(1, min(51, sheet.max_row + 1)):
                    for c_idx in range(1, min(51, sheet.max_column + 1)):
                        cell = sheet.cell(row=r_idx, column=c_idx)
                        if cell.value is not None:
                            excel_headers_map[str(cell.value).strip()] = (r_idx, c_idx)

                updated_count, not_found_dates = 0, []
                for index, source_row in source_df.iterrows():
                    source_date_obj = to_datetime_obj(source_row[date_col_name_csv])
                    if not source_date_obj: continue
                    source_date_key = source_date_obj.strftime('%Y-%m-%d')
                    
                    target_row_num = -1
                    for r_idx in range(1, sheet.max_row + 1):
                        cell_value = sheet.cell(row=r_idx, column=date_col_idx_excel).value
                        cell_date_obj = to_datetime_obj(cell_value)
                        if cell_date_obj and cell_date_obj.strftime('%Y-%m-%d') == source_date_key:
                            target_row_num = r_idx
                            break
                    
                    if target_row_num != -1:
                        for col_name, value in source_row.items():
                            if col_name in excel_headers_map:
                                _, target_col_idx = excel_headers_map[col_name]
                                sheet.cell(row=target_row_num, column=target_col_idx, value=value)
                        updated_count += 1
                    else:
                        not_found_dates.append(source_date_key)
                
                print(f"  ✓ Done: Updated data for {updated_count} dates.")
                if not_found_dates:
                    print(f"  - WARNING: Could not find rows for dates: {', '.join(sorted(not_found_dates))}")
            
            elif strategy == 'append_all':
                for row_data in source_df.values.tolist():
                    sheet.append([None] * (date_col_idx_excel - 1) + row_data)
                print(f"  ✓ Done: Appended {len(source_df)} rows.")

        except Exception as e:
            import traceback
            print(f"  > [FAILED] An unexpected error occurred: {e}")
            print(traceback.format_exc())

    workbook.save(output_path)
    print("\n" + "="*50)
    print(f"🎉 All tasks complete! New file created: {OUTPUT_EXCEL_NAME}")
    print("="*50)

if __name__ == '__main__':
    run_update()
