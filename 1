import os
import glob
import pandas as pd
import openpyxl
from openpyxl.utils import get_column_letter, column_index_from_string
from datetime import datetime
import shutil

# =============================== CONFIGURATION ==================================
# The original Excel template file name
SOURCE_EXCEL_NAME = '需要覆盖的文件.xlsx'

# The name for the output file
OUTPUT_EXCEL_NAME = SOURCE_EXCEL_NAME.replace('.xlsx', '_updated_final.xlsx')

# The configuration map defines which CSV updates which sheet and how.
# Strategies:
# 'update_or_append': Finds a row by date and overwrites it. If not found, appends to the end.
# 'update_and_sort': Rebuilds the sheet's data by combining old and new, sorting it by date. (Correct for '首充复登'/'首充复充')
# 'update_in_place': Special strategy for '推广渠道统计' that updates cells by matching headers.
# 'append_all': Simple strategy to just add all CSV data to the end of the sheet.
REPORT_MAP = {
    '运营统计': ('后台', '时间', 'C', 'update_or_append'),
    'LTV全平台': ('LTV', '时间', 'C', 'update_or_append'),
    '用户留存率(首充复登)_全平台': ('首充复登', '时间', 'I', 'update_and_sort'),
    '用户留存率(首充复充)_全平台': ('首充复充', '时间', 'J', 'update_and_sort'),
    '推广渠道统计-渠道质量': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '推广渠道统计-用户质量': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '推广渠道统计-经济效益': ('推广渠道统计', '日期', 'B', 'update_in_place'),
    '赠送类型统计': ('赠送类型统计', '日期', 'A', 'append_all'),
    '每日渠道统计': ('每日渠道统计', '日期', 'A', 'append_all'),
}
# ========================================================================

def to_datetime_obj(value):
    """Converts a value to a datetime object, returning None if conversion fails."""
    if isinstance(value, datetime):
        return value
    if pd.isna(value) or value is None or str(value).strip() == '':
        return None
    try:
        # This is robust and can handle various date formats
        return pd.to_datetime(str(value))
    except (ValueError, TypeError):
        return None

def run_update():
    """
    Main function to process CSV files and update the master Excel workbook.
    """
    current_directory = os.getcwd()
    source_path = os.path.join(current_directory, SOURCE_EXCEL_NAME)
    output_path = os.path.join(current_directory, OUTPUT_EXCEL_NAME)

    print(f"--- Starting Smart Update ---")

    try:
        shutil.copy(source_path, output_path)
        print(f"✓ Safe copy created: {OUTPUT_EXCEL_NAME}")
    except Exception as e:
        print(f"\n[ERROR] Failed to create a copy: {e}")
        return

    csv_files = glob.glob(os.path.join(current_directory, '*.csv'))
    print(f"✓ Found {len(csv_files)} CSV files to process...")

    workbook = openpyxl.load_workbook(output_path)

    for csv_path in csv_files:
        filename = os.path.basename(csv_path)
        mapping = None
        for keyword, value in sorted(REPORT_MAP.items(), key=lambda item: len(item[0]), reverse=True):
            if keyword in filename:
                mapping = value
                break
        
        if not mapping:
            continue

        sheet_name, date_col_name_csv, date_col_letter_excel, strategy = mapping
        date_col_idx_excel = column_index_from_string(date_col_letter_excel)
        print(f"\n+ Processing '{filename}' -> Sheet: '{sheet_name}' (Strategy: {strategy})")

        try:
            source_df = pd.read_csv(csv_path, keep_default_na=False, dtype=str)
            if source_df.empty:
                print("  - INFO: CSV file is empty, skipping.")
                continue
            
            # Clean up source data
            source_df = source_df[~source_df[date_col_name_csv].astype(str).str.contains("数据汇总")]
            source_df = source_df[source_df[date_col_name_csv].astype(str).str.strip() != '']
            if source_df.empty:
                print("  - INFO: CSV has no valid data rows after cleaning, skipping.")
                continue

            sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(title=sheet_name)

            # Logic for '后台' and 'LTV' (working correctly)
            if strategy == 'update_or_append':
                date_to_row_map = {}
                for row_idx in range(1, sheet.max_row + 1):
                    cell_value = sheet.cell(row=row_idx, column=date_col_idx_excel).value
                    date_obj = to_datetime_obj(cell_value)
                    if date_obj:
                        date_to_row_map[date_obj.strftime('%Y-%m-%d')] = row_idx

                rows_to_append_df, updated_count = [], 0
                for index, source_row in source_df.iterrows():
                    csv_date_obj = to_datetime_obj(source_row[date_col_name_csv])
                    if not csv_date_obj: continue
                    csv_date_key = csv_date_obj.strftime('%Y-%m-%d')
                    
                    if csv_date_key in date_to_row_map:
                        target_row_num = date_to_row_map[csv_date_key]
                        for col_offset, value in enumerate(source_row.values):
                            sheet.cell(row=target_row_num, column=date_col_idx_excel + col_offset, value=value)
                        updated_count += 1
                    else:
                        rows_to_append_df.append(source_row)
                
                if rows_to_append_df:
                    for row_to_append in pd.DataFrame(rows_to_append_df).itertuples(index=False):
                        sheet.append([None] * (date_col_idx_excel - 1) + list(row_to_append))

                print(f"  ✓ Done: Updated {updated_count} rows and appended {len(rows_to_append_df)} new rows.")

            # REBUILT 'update_and_sort' LOGIC (FOR '首充复登', '首充复充')
            elif strategy == 'update_and_sort':
                # Step 1: Find the header row in Excel to define the data area.
                header_row_index = -1
                for i in range(1, min(21, sheet.max_row + 1)):
                    row_values = [str(c.value) for c in sheet[i]]
                    if date_col_name_csv in row_values:
                        header_row_index = i
                        break
                
                if header_row_index == -1:
                    print(f"  - ERROR: Could not find header row with '{date_col_name_csv}'. Skipping.")
                    continue
                
                # Step 2: Read existing data from Excel sheet into a list of lists.
                excel_data_rows = []
                data_start_row = header_row_index + 1
                for row in sheet.iter_rows(min_row=data_start_row, values_only=True):
                    if len(row) >= date_col_idx_excel and row[date_col_idx_excel - 1] is not None:
                        excel_data_rows.append(list(row[date_col_idx_excel - 1:]))

                # Step 3: Create DataFrames using CSV headers as the source of truth.
                excel_df = pd.DataFrame(excel_data_rows, columns=source_df.columns)

                # Step 4: Combine, de-duplicate, and sort the data.
                excel_df[date_col_name_csv] = excel_df[date_col_name_csv].apply(to_datetime_obj)
                source_df[date_col_name_csv] = source_df[date_col_name_csv].apply(to_datetime_obj)
                
                excel_df.dropna(subset=[date_col_name_csv], inplace=True)
                source_df.dropna(subset=[date_col_name_csv], inplace=True)

                combined_df = pd.concat([excel_df, source_df], ignore_index=True)
                combined_df.drop_duplicates(subset=[date_col_name_csv], keep='last', inplace=True)
                combined_df.sort_values(by=date_col_name_csv, inplace=True)

                # Step 5: Safely clear the old data area BELOW the header.
                if sheet.max_row >= data_start_row:
                    sheet.delete_rows(data_start_row, sheet.max_row - data_start_row + 1)
                
                # Step 6: Write the new, sorted data back into the sheet.
                for data_row in combined_df.itertuples(index=False):
                    offset_row = [None] * (date_col_idx_excel - 1) + list(data_row)
                    sheet.append(offset_row)

                print(f"  ✓ Done: Rebuilt and sorted data. Final sheet has {len(combined_df)} data rows.")
            
            # Other strategies that are working correctly.
            elif strategy == 'update_in_place':
                excel_headers_map = {}
                for r_idx in range(1, min(51, sheet.max_row + 1)):
                    for c_idx in range(1, min(51, sheet.max_column + 1)):
                        cell = sheet.cell(row=r_idx, column=c_idx)
                        if cell.value is not None:
                            excel_headers_map[str(cell.value).strip()] = (r_idx, c_idx)

                updated_count, not_found_dates = 0, []
                for index, source_row in source_df.iterrows():
                    source_date_obj = to_datetime_obj(source_row[date_col_name_csv])
                    if not source_date_obj: continue
                    source_date_key = source_date_obj.strftime('%Y-%m-%d')
                    
                    target_row_num = -1
                    for r_idx in range(1, sheet.max_row + 1):
                        cell_value = sheet.cell(row=r_idx, column=date_col_idx_excel).value
                        cell_date_obj = to_datetime_obj(cell_value)
                        if cell_date_obj and cell_date_obj.strftime('%Y-%m-%d') == source_date_key:
                            target_row_num = r_idx
                            break
                    
                    if target_row_num != -1:
                        for col_name, value in source_row.items():
                            if col_name in excel_headers_map:
                                _, target_col_idx = excel_headers_map[col_name]
                                sheet.cell(row=target_row_num, column=target_col_idx, value=value)
                        updated_count += 1
                    else:
                        not_found_dates.append(source_date_key)
                
                print(f"  ✓ Done: Updated data for {updated_count} dates.")
                if not_found_dates:
                    print(f"  - WARNING: Could not find rows for dates: {', '.join(sorted(not_found_dates))}")
            
            elif strategy == 'append_all':
                for row_data in source_df.values.tolist():
                    sheet.append([None] * (date_col_idx_excel - 1) + row_data)
                print(f"  ✓ Done: Appended {len(source_df)} rows.")

        except Exception as e:
            import traceback
            print(f"  > [FAILED] An unexpected error occurred: {e}")
            print(traceback.format_exc())

    workbook.save(output_path)
    print("\n" + "="*50)
    print(f"🎉 All tasks complete! New file created: {OUTPUT_EXCEL_NAME}")
    print("="*50)

if __name__ == '__main__':
    run_update()
